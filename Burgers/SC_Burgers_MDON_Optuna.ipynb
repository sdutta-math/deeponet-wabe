{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 10:44:35.756463: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-20 10:44:35.756538: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-20 10:44:35.760071: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-20 10:44:36.179086: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 10:44:38.040246: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "### -----------------\n",
    "### SD added\n",
    "## Used to suppress TF warnings about 'weighted_metrics' and 'sample_weights'\n",
    "import logging\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "## USE the above to suppress all warning except ERROR. Do not use if debugging or prototyping\n",
    "### -----------------\n",
    "\n",
    "# import keras_tuner\n",
    "tf.keras.backend.set_floatx('float64') \n",
    "\n",
    "import optuna\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, ScalarFormatter, FormatStrFormatter\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "\n",
    "from matplotlib import animation\n",
    "matplotlib.rc('animation', html='html5')\n",
    "from IPython.display import display\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "# Plot parameters\n",
    "plt.rc('font', family='serif')\n",
    "plt.rcParams.update({'font.size': 20,\n",
    "                     'lines.linewidth': 2,\n",
    "                     'lines.markersize':10,\n",
    "                     'axes.labelsize': 16, # fontsize for x and y labels (was 10)\n",
    "                     'axes.titlesize': 20,\n",
    "                     'xtick.labelsize': 16,\n",
    "                     'ytick.labelsize': 16,\n",
    "                     'legend.fontsize': 16,\n",
    "                     'axes.linewidth': 2})\n",
    "\n",
    "import itertools\n",
    "colors = itertools.cycle(['r','g','b','m','y','c'])\n",
    "markers = itertools.cycle(['p','d','o','^','s','x',]) #'D','H','v','*'])\n",
    "\n",
    "\n",
    "from pathlib import Path, PurePath\n",
    "try:\n",
    "    base_dir.exists()\n",
    "except:\n",
    "    curr_dir = Path().resolve()\n",
    "    base_dir = curr_dir.parent  \n",
    "\n",
    "data_dir = \"/work/08372/scai/ls6/deeponet-wabe-main/data/burgers1d\"\n",
    "fig_dir  = \"/work/08372/scai/ls6/deeponet-wabe-main/figures\"\n",
    "scripts_dir  = \"/work/08372/scai/ls6/deeponet-wabe-main/scripts\"\n",
    "work_dir = \"/work/08372/scai/ls6/deeponet-wabe-main/Burgers\"\n",
    "model_dir = \"/work/08372/scai/ls6/deeponet-wabe-main/model\"\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "\n",
    "sys.path.append(r'/work/08372/scai/ls6/deeponet-wabe-main/scripts')\n",
    "sys.path.append(r'/work/08372/scai/ls6/deeponet-wabe-main/Burgers')\n",
    "sys.path.append(r'/work/08372/scai/ls6/deeponet-wabe-main/Burgers/functions')\n",
    "\n",
    "import modified_don as don\n",
    "import burgers_exact as bg\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "case='Train' #or 'Predict'\n",
    "\n",
    "if case == 'Predict':\n",
    "    \n",
    "    ## Replace below with appropriate timestamp of saved model\n",
    "    model_path = model_dir+'_burgers1d_'+timestamp_don\n",
    "\n",
    "    loaded_model = tf.keras.models.load_model(model_path)\n",
    "    branch_id = np.load(model_path+'/branch_id.npy')\n",
    "\n",
    "# train_epochs=2\n",
    "\n",
    "# train_epochs = 10000\n",
    "# optuna_epochs = 2000\n",
    "# optuna_trials = 500\n",
    "\n",
    "train_epochs = 2\n",
    "optuna_epochs = 2\n",
    "optuna_trials = 3\n",
    "\n",
    "loss='mse'\n",
    "optimizer_str='adam'\n",
    "scaling=False\n",
    "scaler_min=0\n",
    "scaler_max=1\n",
    "re_train_list=[15,25,35,50,70,100,200,400,800]\n",
    "re_val_list=[10,1000]\n",
    "re_test_list=[10,30,75,150,300,600,1000]\n",
    "x_extent_train=0.8\n",
    "t_extent_train=1.6\n",
    "x_extent_val=1\n",
    "t_extent_val=2\n",
    "percent_branch=0.05\n",
    "percent_trunk=0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_grid(L, T, vxn, vtn):\n",
    "    vx = np.linspace(0,L,vxn)\n",
    "    vt = np.linspace(0,T,vtn)\n",
    "    return vx, vt\n",
    "\n",
    "def plot_bounds_1d(p1,p2,p3,L,T, label1=None, vmin1=None, vmax1=None, name=None):\n",
    "    \n",
    "    if vmin1 is None:\n",
    "        vmin1 = np.amin([p1.min(), p2.min()])\n",
    "        vmax1 = np.amax([p1.max(), p2.max()])\n",
    "\n",
    "    fig, ((ax1), (ax2), (ax3)) = plt.subplots(1,3, figsize=(20,3))\n",
    "    pcm1 = ax1.imshow(p1,cmap='jet',origin='lower',\n",
    "                      vmin=vmin1, vmax=vmax1, extent=(0,T,0,L), aspect = 0.79)\n",
    "    ax1.yaxis.set_ticks(np.arange(0,L+0.1,1))\n",
    "    fig.colorbar(pcm1,ax=ax1)\n",
    "    ax1.set_title('Truth' +'\\n'+ '%s = %.2f'%('Re', label1)+'\\n'+\n",
    "                 '%.4f<u<%.4f'%(tf.reduce_min(p1).numpy(), tf.reduce_max(p1).numpy()))\n",
    "    pcm2 = ax2.imshow(p2,cmap='jet',origin='lower',\n",
    "                      vmin=vmin1, vmax=vmax1, extent=(0,T,0,L), aspect = 0.79)\n",
    "    ax2.yaxis.set_ticks(np.arange(0,L+0.1,1))\n",
    "\n",
    "    fig.colorbar(pcm2,ax=ax2)\n",
    "    ax2.set_title('Prediction' +'\\n'+ '%s = %.2f'%('Re', label1)+'\\n'\n",
    "                 '%.4f<u<%.4f'%(tf.reduce_min(p2).numpy(), tf.reduce_max(p2).numpy()))\n",
    "    pcm3 = ax3.imshow(p3,cmap='coolwarm',origin='lower',\n",
    "                      vmin=-0.05, vmax=0.05, extent=(0,T,0,L), aspect = 0.79)\n",
    "    ax3.yaxis.set_ticks(np.arange(0,L+0.1,1))\n",
    "\n",
    "    cbar = fig.colorbar(pcm3,ax=ax3)\n",
    "    ax3.set_title('Relative Error' +'\\n'+ '%s = %.2f'%('Re', label1))\n",
    "    \n",
    "    ax1.set_ylabel('$x$',fontsize=18)\n",
    "    ax1.set_xlabel('$t$',fontsize=18)\n",
    "    ax2.set_xlabel('$t$',fontsize=18) \n",
    "    ax3.set_xlabel('$t$',fontsize=18)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "#     plt.savefig(name)\n",
    "\n",
    "def plot_spcaetime_1d(p1,p2,p3,p4,p5,p6,T,L, colormap='jet', label1=None, label2=None, vmin1=None, vmax1=None, name=None):\n",
    "    \"\"\"\n",
    "    Plot space-time 2d plots of 1D solutions\n",
    "    Row1 : Predicted, True, Error for Soln1\n",
    "    Row2 : Predicted, True, Error for Soln2\n",
    "    \"\"\"\n",
    "    f = plt.figure(figsize=(15,10))\n",
    "    gs = gridspec.GridSpec(3, 3, )\n",
    "    gs.update(wspace=0.2, hspace=0.2) # set the spacing between axes.\n",
    "\n",
    "    if vmin1 is None:\n",
    "        vmin1 = np.amin([p1.min(), p2.min(), p3.min(), p4.min()])\n",
    "        vmax1 = np.amax([p1.max(), p2.max(), p3.max(), p4.max()])\n",
    "\n",
    "    ax1 = plt.subplot(gs[0, 0]);\n",
    "    f1= ax1.imshow(p1,cmap=colormap,origin='lower',vmin=vmin1, vmax=vmax1, extent=(0,T,0,L), aspect = 0.59)\n",
    "    ax1.yaxis.set_ticks(np.arange(0,L+0.1,1)); ax1.xaxis.set_ticks(np.arange(0,T+0.1,1))\n",
    "    ax1.set_title('%s=%.2f'%('Re',label1[0]))\n",
    "\n",
    "    ax2 = plt.subplot(gs[0, 1]);\n",
    "    f2 = ax2.imshow(p2,cmap=colormap,origin='lower',vmin=vmin1, vmax=vmax1, extent=(0,T,0,L), aspect = 0.59)\n",
    "    ax2.yaxis.set_ticks(np.arange(0,L+0.1,1)); ax2.xaxis.set_ticks(np.arange(0,T+0.1,1))\n",
    "    ax2.set_title('%s=%.2f'%('Re',label1[1]))\n",
    "\n",
    "    ax3 = plt.subplot(gs[1, 0]);\n",
    "    f3= ax3.imshow(p3,cmap=colormap,origin='lower',vmin=vmin1, vmax=vmax1, extent=(0,T,0,L), aspect = 0.59)\n",
    "    ax3.set_xticklabels([]); ax3.set_yticklabels([])\n",
    "#     ax3.yaxis.set_ticks(np.arange(0,1.1,1))\n",
    "    ax3.set_title('%s=%.2f'%('Re',label1[2]))\n",
    "\n",
    "    ax4 = plt.subplot(gs[1, 1]);\n",
    "    f4 = ax4.imshow(p4,cmap=colormap,origin='lower',vmin=vmin1, vmax=vmax1, extent=(0,T,0,L), aspect = 0.59)\n",
    "    ax4.set_xticklabels([]); ax4.set_yticklabels([])\n",
    "    ax4.set_title('%s=%.2f'%('Re',label1[3]))\n",
    "    \n",
    "    ax5 = plt.subplot(gs[2, 0]);\n",
    "    f5= ax5.imshow(p5,cmap=colormap,origin='lower',vmin=vmin1, vmax=vmax1, extent=(0,T,0,L), aspect = 0.59)\n",
    "    ax5.set_xticklabels([]); ax5.set_yticklabels([])\n",
    "#     ax3.yaxis.set_ticks(np.arange(0,1.1,1))\n",
    "    ax5.set_title('%s=%.2f'%('Re',label1[4]))\n",
    "\n",
    "    ax6 = plt.subplot(gs[2, 1]);\n",
    "    f6 = ax6.imshow(p6,cmap=colormap,origin='lower',vmin=vmin1, vmax=vmax1, extent=(0,T,0,L), aspect = 0.59)\n",
    "    cbar1 = f.colorbar(f6, ax=list((ax1, ax2, ax3, ax4, ax5, ax6)),orientation='horizontal',aspect=50, pad=0.1)\n",
    "    ax6.set_xticklabels([]); ax6.set_yticklabels([])\n",
    "    ax6.set_title('%s=%.2f'%('Re',label1[5]))\n",
    "\n",
    "    ax1.set_ylabel('$x$',fontsize=18); #ax2.set_ylabel('$x$',fontsize=18);\n",
    "    ax3.set_ylabel('$x$',fontsize=18); #ax4.set_ylabel('$x$',fontsize=18);\n",
    "\n",
    "    ax5.set_xlabel('$t$',fontsize=18); ax6.set_xlabel('$t$',fontsize=18); \n",
    "    ax5.set_ylabel('$x$',fontsize=18); #ax6.set_ylabel('$x$',fontsize=18);\n",
    "#     plt.savefig(name)\n",
    "\n",
    "\n",
    "def multiple_burgers(Re_list,vxn,vx,vtn,vt,percent_branch,percent_trunk,id_branch=None):\n",
    "    \n",
    "    number_cases = len(Re_list)\n",
    "    branch_sensors = int(vxn*percent_branch)\n",
    "    trunk_sensors = int(vtn*vxn*percent_trunk)\n",
    "    \n",
    "    burgers_array = np.zeros((number_cases,vxn,vtn))\n",
    "    burgers_flatten = np.zeros((number_cases*vxn*vtn))\n",
    "    count = 0 \n",
    "    id0 = 0\n",
    "    id1 = vxn*vtn\n",
    "    \n",
    "    for Re in Re_list:\n",
    "        solution = np.zeros((vxn,vtn))\n",
    "        for ix,vxi in enumerate(vx):\n",
    "            solution[ix] = bg.true_solution(vxi,vt,Re)\n",
    "        burgers_array[count] = solution\n",
    "        burgers_flatten[id0:id1] = (solution.flatten())\n",
    "        count = count + 1\n",
    "        id0 = id1\n",
    "        id1 = id1 + vxn*vtn\n",
    "        \n",
    "    b0 = burgers_array[:,:,0] #u0\n",
    "    \n",
    "    if id_branch is not None:\n",
    "        id_b=np.zeros(np.shape(id_branch),dtype=int)\n",
    "        for i in range(len(id_branch[0])):\n",
    "            smallest=np.absolute(vx-id_branch[1][i])\n",
    "            id_b[0][i]=int(np.argmin(smallest))\n",
    "        id_b[1]=id_branch[1]    \n",
    "    else:\n",
    "        id_b = np.sort(np.random.choice(vxn, branch_sensors, replace=False))\n",
    "        b_coords = vx[id_b]\n",
    "        id_b = [id_b, b_coords]\n",
    "\n",
    "    b0_train = b0[:,id_b[0]]\n",
    "\n",
    "    \n",
    "    T, X = np.meshgrid(vt,vx)\n",
    "    for i in range(number_cases):\n",
    "        b0_vector = np.tile(np.expand_dims(b0_train[i],1),vtn*vxn).T\n",
    "        \n",
    "        id_t = np.sort(np.random.choice(vtn*vxn, trunk_sensors, replace=False))\n",
    "        \n",
    "        if i == 0:\n",
    "            b_input = b0_vector[id_t]\n",
    "            t_input = np.hstack([T.flatten()[id_t,None], X.flatten()[id_t,None]])\n",
    "            target = burgers_array[i,:,:].flatten()[id_t,None]\n",
    "\n",
    "        else:\n",
    "            b_input = np.vstack([b_input,b0_vector[id_t]])\n",
    "            t_input = np.vstack([t_input,np.hstack([T.flatten()[id_t,None], X.flatten()[id_t,None]])])\n",
    "            target = np.vstack([target,burgers_array[i,:,:].flatten()[id_t,None]])        \n",
    "    \n",
    "    return burgers_array, burgers_flatten, b_input, t_input, target, id_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re_train = [15,25,50,75,100,150,200,300,400,600,800,900]\n",
    "Re_train =  re_train_list\n",
    "L_train =  x_extent_train\n",
    "T_train =  t_extent_train\n",
    "vxn = 300\n",
    "vtn = 500\n",
    "vx, vt = define_grid(L_train, T_train, vxn, vtn)\n",
    "percent_branch =  percent_branch\n",
    "percent_trunk =  percent_trunk\n",
    "burgers_array_train, burgers_flatten_train, b_train, \\\n",
    "                    t_train, target_train, id_branch = multiple_burgers(Re_train,vxn,vx,vtn,vt,\n",
    "                                                            percent_branch,percent_trunk)\n",
    "\n",
    "if case == 'Predict':\n",
    "    id_branch=branch_id\n",
    "    \n",
    "Re_val =  re_val_list\n",
    "L_val =  x_extent_val\n",
    "T_val =  t_extent_val\n",
    "vxn = 300\n",
    "vtn = 500\n",
    "vx, vt = define_grid(L_val, T_val, vxn, vtn)\n",
    "percent_branch =  percent_branch\n",
    "percent_trunk =  percent_trunk\n",
    "burgers_array_val, burgers_flatten_val, b_val, \\\n",
    "                    t_val, target_val, _ = multiple_burgers(Re_val,vxn,vx,vtn,vt,\n",
    "                                                         percent_branch,percent_trunk,id_branch=id_branch)\n",
    "\n",
    "Re_test =  re_test_list\n",
    "L_test = L_val\n",
    "T_test = T_val\n",
    "vxn = 300\n",
    "vtn = 500\n",
    "vx, vt = define_grid(L_test, T_test, vxn, vtn)\n",
    "percent_branch = 0.05\n",
    "percent_trunk = 1\n",
    "burgers_array_test, burgers_flatten_test, b_test, \\\n",
    "                    t_test, target_test, _ = multiple_burgers(Re_test,vxn,vx,vtn,vt, \n",
    "                                                              percent_branch,percent_trunk,id_branch)\n",
    "\n",
    "if  scaling is True:\n",
    "    x_scaler = MinMaxScaler(feature_range=( scaler_min,  scaler_max))\n",
    "    t_scaler = MinMaxScaler(feature_range=( scaler_min,  scaler_max))\n",
    "    u_scaler = MinMaxScaler(feature_range=( scaler_min,  scaler_max))\n",
    "    b_scaler = MinMaxScaler(feature_range=( scaler_min,  scaler_max))\n",
    "\n",
    "    x_scaler.fit(np.expand_dims(t_val[:,0],1))\n",
    "    t_scaler.fit(np.expand_dims(t_val[:,1],1))\n",
    "    u_scaler.fit(target_val)\n",
    "    b_scaler.fit(b_val)\n",
    "\n",
    "    t_train[:,0] = np.squeeze(x_scaler.transform(np.expand_dims(t_train[:,0],1)))\n",
    "    t_train[:,1] = np.squeeze(t_scaler.transform(np.expand_dims(t_train[:,1],1)))\n",
    "    b_train = b_scaler.transform(b_train)\n",
    "    target_train = u_scaler.transform(target_train)\n",
    "    \n",
    "    t_val[:,0] = np.squeeze(x_scaler.transform(np.expand_dims(t_val[:,0],1)))\n",
    "    t_val[:,1] = np.squeeze(t_scaler.transform(np.expand_dims(t_val[:,1],1)))\n",
    "    b_val = b_scaler.transform(b_val)\n",
    "    target_val = u_scaler.transform(target_val)\n",
    "    \n",
    "    t_test[:,0] = np.squeeze(x_scaler.transform(np.expand_dims(t_test[:,0],1)))\n",
    "    t_test[:,1] = np.squeeze(t_scaler.transform(np.expand_dims(t_test[:,1],1)))\n",
    "    b_test = b_scaler.transform(b_test)\n",
    "    target_test = u_scaler.transform(target_test)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(trial):\n",
    "    # Define search space\n",
    "    verbosity_mode = 1\n",
    "\n",
    "    branch_sensors = int(vxn* percent_branch)\n",
    "    branch_output_shape = trial.suggest_int(\"b_output_shape\",64,512,64)\n",
    "    b_number_layers = trial.suggest_int(\"b_layers\",1,6)\n",
    "    b_neurons_layer = trial.suggest_int(\"b_neurons_layers\",32,256,32)\n",
    "    b_actf = trial.suggest_categorical(\"b_actf\", [\"relu\", \"elu\", \"tanh\", \"swish\", \"sigmoid\"])\n",
    "    b_regularizer = trial.suggest_categorical(\"b_regularizer\", [\"none\", \"l1\", \"l2\"]) \n",
    "    b_initializer = trial.suggest_categorical(\"b_initializer\", [\"glorot_normal\", \"glorot_uniform\", \"he_normal\", \"he_uniform\"])\n",
    "    \n",
    "    b_encoder_layers= trial.suggest_int(\"b_encoder_layers\",1,6) \n",
    "    b_encoder_neurons= trial.suggest_int(\"b_encoder_neurons\",32,256,32) \n",
    "    b_encoder_actf= trial.suggest_categorical(\"b_encoder_actf\", [\"relu\", \"elu\", \"tanh\", \"swish\", \"sigmoid\"])\n",
    "    b_encoder_init= trial.suggest_categorical(\"b_encoder_initializer\", [\"glorot_normal\", \"glorot_uniform\", \"he_normal\", \"he_uniform\"])\n",
    "    b_encoder_regularizer=trial.suggest_categorical(\"b_encoder_regularizer\", [\"none\", \"l1\", \"l2\"])  \n",
    "    \n",
    "    t_number_layers = trial.suggest_int(\"t_layers\",1,6)\n",
    "    t_neurons_layer = trial.suggest_int(\"b_neurons_layers\",32,256,32)\n",
    "    t_actf = trial.suggest_categorical(\"t_actf\", [\"relu\", \"elu\", \"tanh\", \"swish\"])\n",
    "    t_regularizer = trial.suggest_categorical(\"t_regularizer\", [\"none\", \"l1\", \"l2\"]) \n",
    "    t_initializer = trial.suggest_categorical(\"t_initializer\", [\"glorot_normal\", \"glorot_uniform\", \"he_normal\", \"he_uniform\"]) \n",
    "    init_lr = trial.suggest_categorical(\"ilr\", [1e-6, 5e-6, 1e-5, 5e-5, 1e-4, 1e-3 ])\n",
    "    \n",
    "    t_encoder_layers=trial.suggest_int(\"t_encoder_layers\",1,6)  \n",
    "    t_encoder_neurons= trial.suggest_int(\"t_encoder_neurons\",32,256,32)  \n",
    "    t_encoder_actf= trial.suggest_categorical(\"t_encoder_actf\", [\"relu\", \"elu\", \"tanh\", \"swish\", \"sigmoid\"]) \n",
    "    t_encoder_init= trial.suggest_categorical(\"t_encoder_initializer\", [\"glorot_normal\", \"glorot_uniform\", \"he_normal\", \"he_uniform\"]) \n",
    "    t_encoder_regularizer= trial.suggest_categorical(\"t_encoder_regularizer\", [\"none\", \"l1\", \"l2\"]) \n",
    "\n",
    "\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(init_lr)  \n",
    "\n",
    "    loss_obj = tf.keras.losses.MeanSquaredError()\n",
    "    \n",
    "\n",
    "#     nn = don.don_nn(branch_input_shape = branch_sensors,\n",
    "#                 branch_output_shape = branch_output_shape,\n",
    "#                 b_number_layers = b_number_layers, \n",
    "#                 b_neurons_layer = b_neurons_layer, \n",
    "#                 b_actf = b_actf, \n",
    "#                 b_init = b_initializer, \n",
    "#                 b_regularizer = b_regularizer, \n",
    "#                 trunk_input_shape = 2, \n",
    "#                 trunk_output_shape = branch_output_shape,  ### Needs to be same as branch output shape\n",
    "#                 t_number_layers = t_number_layers, \n",
    "#                 t_neurons_layer = t_neurons_layer, \n",
    "#                 t_actf = t_actf, \n",
    "#                 t_init = t_initializer, \n",
    "#                 t_regularizer = t_regularizer,\n",
    "#                )\n",
    "    nn = don.don_nn(branch_input_shape = branch_sensors,\n",
    "                branch_output_shape = branch_output_shape,\n",
    "                b_number_layers = b_number_layers, \n",
    "                b_neurons_layer = b_neurons_layer, \n",
    "                b_actf = b_actf, \n",
    "                b_init = b_initializer, \n",
    "                b_regularizer = b_regularizer, \n",
    "                    \n",
    "                b_encoder_layers= b_encoder_layers, \n",
    "                b_encoder_neurons= b_encoder_neurons,\n",
    "                b_encoder_actf= b_encoder_actf, \n",
    "                b_encoder_init= b_encoder_init, \n",
    "                b_encoder_regularizer= b_encoder_regularizer, \n",
    "                    \n",
    "                trunk_input_shape = 2, \n",
    "                trunk_output_shape = branch_output_shape,  ### Needs to be same as branch output shape\n",
    "                t_number_layers = t_number_layers, \n",
    "                t_neurons_layer = t_neurons_layer, \n",
    "                t_actf = t_actf, \n",
    "                t_init = t_initializer, \n",
    "                t_regularizer = t_regularizer,\n",
    "                \n",
    "                t_encoder_layers= t_encoder_layers, \n",
    "                t_encoder_neurons= t_encoder_neurons, \n",
    "                t_encoder_actf= t_encoder_actf, \n",
    "                t_encoder_init= t_encoder_init, \n",
    "                t_encoder_regularizer= t_encoder_regularizer,  \n",
    "               )\n",
    "    \n",
    "    model = don.don_model(nn)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer = optimizer,\n",
    "        loss_fn = loss_obj)\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FYI: Objective functions can take additional arguments\n",
    "# (https://optuna.readthedocs.io/en/stable/faq.html#objective-func-additional-args).\n",
    "\n",
    "\n",
    "# Wrap training step for search\n",
    "def objective(trial):\n",
    "\n",
    "    # Clear clutter from previous Keras session graphs.\n",
    "    clear_session()\n",
    "\n",
    "    # Build model and optimizer.\n",
    "    model = NN(trial)\n",
    "\n",
    "    ## TODO::: CAN THIS BE OPTIMIZED??\n",
    "    percent_trunk = 0.05\n",
    "    \n",
    "    buffer_size = int(vtn*vxn*percent_trunk*len( re_train_list))\n",
    "    batch_size = trial.suggest_int(\"batch_size\",256,buffer_size//25,512)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((b_train,t_train, target_train))\n",
    "    dataset = dataset.shuffle(buffer_size=buffer_size).batch(batch_size)\n",
    "    \n",
    "    # batch_size = int(vtn*vxn* percent_trunk*len( re_val_list))\n",
    "    \n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((b_val,t_val, target_val))\n",
    "    val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "    \n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.9,\n",
    "                        patience=10000, min_lr=1e-8, min_delta=0, verbose=1) \n",
    "    \n",
    "    history = model.fit(dataset,validation_data=val_dataset,\n",
    "                        epochs = optuna_epochs)#, callbacks=[reduce_lr])\n",
    "    \n",
    "    score = model.evaluate(val_dataset, verbose=0)\n",
    "    \n",
    "    print(score)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 10:46:09,295] A new study created in memory with name: no-name-43184575-b46b-4af4-b9fb-3bd3f123cb6e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.int32, name=None), inferred_value=[None, 128], name='tf.compat.v1.shape/Shape:0', description=\"created by layer 'tf.compat.v1.shape'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.int32, name=None), inferred_value=[None, 2], name='tf.compat.v1.shape_1/Shape:0', description=\"created by layer 'tf.compat.v1.shape_1'\") KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.int32, name=None), inferred_value=[None, 128], name='tf.compat.v1.shape_2/Shape:0', description=\"created by layer 'tf.compat.v1.shape_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.int32, name=None), inferred_value=[None, 128], name='tf.compat.v1.shape_3/Shape:0', description=\"created by layer 'tf.compat.v1.shape_3'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.int32, name=None), inferred_value=[None, 2], name='tf.compat.v1.shape_4/Shape:0', description=\"created by layer 'tf.compat.v1.shape_4'\") KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.int32, name=None), inferred_value=[None, 128], name='tf.compat.v1.shape_5/Shape:0', description=\"created by layer 'tf.compat.v1.shape_5'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.int32, name=None), inferred_value=[None, 128], name='tf.compat.v1.shape_6/Shape:0', description=\"created by layer 'tf.compat.v1.shape_6'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.int32, name=None), inferred_value=[None, 2], name='tf.compat.v1.shape_7/Shape:0', description=\"created by layer 'tf.compat.v1.shape_7'\") KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.int32, name=None), inferred_value=[None, 128], name='tf.compat.v1.shape_8/Shape:0', description=\"created by layer 'tf.compat.v1.shape_8'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.int32, name=None), inferred_value=[None, 128], name='tf.compat.v1.shape_9/Shape:0', description=\"created by layer 'tf.compat.v1.shape_9'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.int32, name=None), inferred_value=[None, 2], name='tf.compat.v1.shape_10/Shape:0', description=\"created by layer 'tf.compat.v1.shape_10'\") KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.int32, name=None), inferred_value=[None, 128], name='tf.compat.v1.shape_11/Shape:0', description=\"created by layer 'tf.compat.v1.shape_11'\")\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "Epoch 1/2\n",
      "264/264 [==============================] - 6s 13ms/step - loss: 0.1622 - val_loss: 0.1455 - lr: 5.0000e-06\n",
      "Epoch 2/2\n",
      "264/264 [==============================] - 3s 12ms/step - loss: 0.0933 - val_loss: 0.1084 - lr: 5.0000e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 10:46:19,545] Trial 0 finished with value: 0.10840793077464167 and parameters: {'b_output_shape': 384, 'b_layers': 4, 'b_neurons_layers': 128, 'b_actf': 'elu', 'b_regularizer': 'none', 'b_initializer': 'he_uniform', 'b_encoder_layers': 1, 'b_encoder_neurons': 20, 'b_encoder_actf': 'swish', 'b_encoder_initializer': 'he_uniform', 'b_encoder_regularizer': 'l2', 't_layers': 1, 't_actf': 'relu', 't_regularizer': 'l2', 't_initializer': 'he_uniform', 'ilr': 5e-06, 't_encoder_layers': 5, 't_encoder_neurons': 68, 't_encoder_actf': 'elu', 't_encoder_initializer': 'glorot_uniform', 't_encoder_regularizer': 'l1', 'batch_size': 256}. Best is trial 0 with value: 0.10840793077464167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10840793077464167\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.int32, name=None), inferred_value=[None, 128], name='tf.compat.v1.shape/Shape:0', description=\"created by layer 'tf.compat.v1.shape'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.int32, name=None), inferred_value=[None, 2], name='tf.compat.v1.shape_1/Shape:0', description=\"created by layer 'tf.compat.v1.shape_1'\") KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.int32, name=None), inferred_value=[None, 128], name='tf.compat.v1.shape_2/Shape:0', description=\"created by layer 'tf.compat.v1.shape_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.int32, name=None), inferred_value=[None, 128], name='tf.compat.v1.shape_3/Shape:0', description=\"created by layer 'tf.compat.v1.shape_3'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.int32, name=None), inferred_value=[None, 2], name='tf.compat.v1.shape_4/Shape:0', description=\"created by layer 'tf.compat.v1.shape_4'\") KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.int32, name=None), inferred_value=[None, 128], name='tf.compat.v1.shape_5/Shape:0', description=\"created by layer 'tf.compat.v1.shape_5'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.int32, name=None), inferred_value=[None, 128], name='tf.compat.v1.shape_6/Shape:0', description=\"created by layer 'tf.compat.v1.shape_6'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.int32, name=None), inferred_value=[None, 2], name='tf.compat.v1.shape_7/Shape:0', description=\"created by layer 'tf.compat.v1.shape_7'\") KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.int32, name=None), inferred_value=[None, 128], name='tf.compat.v1.shape_8/Shape:0', description=\"created by layer 'tf.compat.v1.shape_8'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.int32, name=None), inferred_value=[None, 128], name='tf.compat.v1.shape_9/Shape:0', description=\"created by layer 'tf.compat.v1.shape_9'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.int32, name=None), inferred_value=[None, 2], name='tf.compat.v1.shape_10/Shape:0', description=\"created by layer 'tf.compat.v1.shape_10'\") KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.int32, name=None), inferred_value=[None, 128], name='tf.compat.v1.shape_11/Shape:0', description=\"created by layer 'tf.compat.v1.shape_11'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.int32, name=None), inferred_value=[None, 128], name='tf.compat.v1.shape_12/Shape:0', description=\"created by layer 'tf.compat.v1.shape_12'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.int32, name=None), inferred_value=[None, 2], name='tf.compat.v1.shape_13/Shape:0', description=\"created by layer 'tf.compat.v1.shape_13'\") KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.int32, name=None), inferred_value=[None, 128], name='tf.compat.v1.shape_14/Shape:0', description=\"created by layer 'tf.compat.v1.shape_14'\")\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "Epoch 1/2\n",
      "88/88 [==============================] - 7s 35ms/step - loss: 0.0217 - val_loss: 0.0691 - lr: 5.0000e-05\n",
      "Epoch 2/2\n",
      "10/88 [==>...........................] - ETA: 2s - loss: 0.0143"
     ]
    }
   ],
   "source": [
    "## OPTUNA Trials\n",
    "\n",
    "# Define search parameters\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials = optuna_trials, timeout = 100000)\n",
    "\n",
    "\n",
    "#\n",
    "original_stdout = sys.stdout\n",
    "\n",
    "sys.stdout = open(f\"burgers1d_don_optuna.txt\", \"w\")\n",
    "#\n",
    "\n",
    "# Print results\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for keyy, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(keyy, value))\n",
    "\n",
    "print(\"Importance:\")\n",
    "print(optuna.importance.get_param_importances(study))\n",
    "\n",
    "\n",
    "#\n",
    "sys.stdout = original_stdout # Reset the standard output to its original value\n",
    "#\n",
    "\n",
    "#export DataFrame to text file (keep header row and index column)\n",
    "with open(f'burgers1d_don_trials.txt', 'a') as f:\n",
    "    df_string = study.trials_dataframe().sort_values(\"value\").to_string()\n",
    "    f.write(df_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/08372/scai/.local/lib/python3.9/site-packages/optuna/distributions.py:700: UserWarning: The distribution is specified by [4, 128] and step=16, but the range is not divisible by `step`. It will be replaced by [4, 116].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "Epoch 1/2\n",
      "264/264 [==============================] - 18s 47ms/step - loss: 0.0237 - val_loss: 0.0369 - lr: 5.0000e-05\n",
      "Epoch 2/2\n",
      "264/264 [==============================] - 11s 43ms/step - loss: 0.0091 - val_loss: 0.0379 - lr: 5.0000e-05\n",
      "Training time: 0 H 0 M, 29 S\n"
     ]
    }
   ],
   "source": [
    "# branch_sensors = int(vxn* percent_branch)\n",
    "\n",
    "##DON Model Training\n",
    "model = NN(trial)\n",
    "\n",
    "batch_size = trial.params['batch_size']\n",
    "\n",
    "## This definition needs to change if \"percent_trunk\" is also optimizer by Optuna\n",
    "buffer_size = int(vtn*vxn*percent_trunk*len( re_train_list))\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((b_train,t_train, target_train))\n",
    "dataset = dataset.shuffle(buffer_size=buffer_size).batch(batch_size)\n",
    "   \n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((b_val,t_val, target_val))\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.9,\n",
    "                          patience=10000, min_lr=1e-6, min_delta=1e-10, verbose=1)\n",
    "\n",
    "don_checkpoint_filepath = './tmp/checkpoint_burgers1d_don'\n",
    "model_check = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=don_checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "# early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "#     monitor='val_loss',\n",
    "#     min_delta=1e-8,\n",
    "#     patience=500,\n",
    "#     verbose=1,\n",
    "#     restore_best_weights=True\n",
    "# )\n",
    "\n",
    "i=1\n",
    "\n",
    "timestamp_don = datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "out_dir = os.path.join(model_dir, 'burgers1d_don_'+timestamp_don) \n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "\n",
    "    \n",
    "\n",
    "if case == 'Train':\n",
    "    \n",
    "    init_time = time.time()\n",
    "    \n",
    "    model.fit(dataset, validation_data=val_dataset, epochs= train_epochs,\n",
    "              callbacks=[reduce_lr, model_check ])  # early_stop,])  ## Removed by SD\n",
    "                 \n",
    "    \n",
    "    end_time = time.time()\n",
    "    train_time = end_time - init_time\n",
    "    hrs = int(train_time//3600); rem_time = train_time - hrs*3600\n",
    "    mins = int(rem_time//60); secs = int(rem_time%60)\n",
    "    print('Training time: %d H %d M, %d S'%(hrs,mins,secs))\n",
    "    \n",
    "    \n",
    "    model.save(out_dir,id_branch,)\n",
    "    np.savez('burgers1d_don_history_'+timestamp_don, history=model.history.history, allow_pickle=True,)\n",
    "\n",
    "if case == 'Predict':   \n",
    "    model = loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Learning rate decay')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = model.history.history['loss']\n",
    "val_loss = model.history.history['val_loss']\n",
    "lrate = model.history.history['lr']\n",
    "train_epoch = model.history.epoch\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1,ncols=2,figsize=(14,5),constrained_layout=True)\n",
    "ax[0].plot(train_epoch,train_loss,label='train_loss',marker='v',markevery=128)\n",
    "ax[0].plot(train_epoch,val_loss,label='val_loss',marker='s',markevery=128)\n",
    "\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].set_title('Validation and Training losses in semi-log scale')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(train_epoch,lrate,label='LR',marker='p',markevery=128)\n",
    "ax[1].set_yscale('log')\n",
    "\n",
    "ax[1].set_title('Learning rate decay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_t = np.argmin(np.abs(vt-1.6))\n",
    "id_x = np.argmin(np.abs(vx-0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_730888/2807808849.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mo_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m  \u001b[0mscaling\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mo_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "o_res = model([b_test,t_test])\n",
    "\n",
    "if  scaling is True:\n",
    "    o_res = u_scaler.inverse_transform(o_res)\n",
    "\n",
    "test = np.reshape(np.array(o_res),(len( re_test_list),vxn,vtn))\n",
    "\n",
    "error = test - burgers_array_test\n",
    "\n",
    "plot_bounds_1d(burgers_array_test[0],test[0],error[0], L_test, T_test, label1= re_test_list[0], vmin1=0, vmax1=0.5,name='low_re'+str(i))\n",
    "plot_bounds_1d(burgers_array_test[-1],test[-1],error[-1], L_test, T_test, label1= re_test_list[-1], vmin1=0, vmax1=0.5, name='high_re'+str(i))\n",
    "\n",
    "test[:,:,id_t]=1000\n",
    "test[:,id_x,:]=1000\n",
    "burgers_array_test[:,:,id_t]=1000\n",
    "burgers_array_test[:,id_x,:]=1000\n",
    "error[:,:,id_t]=1000\n",
    "error[:,id_x,:]=1000\n",
    "\n",
    "plot_spcaetime_1d(test[0],test[1],\n",
    "                  test[2],test[3],\n",
    "                  test[4],test[5],\n",
    "                  T_test,L_test,label1= re_test_list,\n",
    "                  vmin1=0,\n",
    "                  vmax1=0.5,                      \n",
    "                  name='prediction'+str(i))\n",
    "\n",
    "plot_spcaetime_1d(error[0],error[1],\n",
    "                  error[2],error[3],\n",
    "                  error[4],error[5],\n",
    "                  T_test,L_test,\n",
    "                  colormap='coolwarm',label1= re_test_list,\n",
    "                  vmin1=-0.05,\n",
    "                  vmax1=0.05,\n",
    "                  name='error'+str(i))\n",
    "\n",
    "plot_spcaetime_1d(burgers_array_train[0],burgers_array_train[1],\n",
    "                  burgers_array_train[2],burgers_array_train[3],\n",
    "                  burgers_array_train[4],burgers_array_train[5],\n",
    "                  T_train,L_train,label1= re_train_list,\n",
    "                  vmin1=0,\n",
    "                  vmax1=0.5,                  \n",
    "                  name='train') \n",
    "\n",
    "plot_spcaetime_1d(burgers_array_test[0],burgers_array_test[1],\n",
    "                  burgers_array_test[2],burgers_array_test[3],\n",
    "                  burgers_array_test[4],burgers_array_test[5],\n",
    "                  T_test,L_test,label1= re_test_list,\n",
    "                  vmin1=0,\n",
    "                  vmax1=0.5,    \n",
    "                  name='truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
