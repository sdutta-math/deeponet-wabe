{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3cc9427",
   "metadata": {},
   "source": [
    "## Notebook to test a vanilla DeepONet on a 1d Burgers example\n",
    "\n",
    "Consider the one-dimensional viscous Burgers' equation with Dirichlet boundary conditions which can be represented as \n",
    "\\begin{align}\n",
    "\\dot{u} + u \\frac{\\partial u}{\\partial x} = \\nu \\frac{\\partial^2 u}{\\partial x^2},\\\\\n",
    "u(x,0) = u_0, \\qquad x \\in [0,L], \\qquad u(0,t) = u(L.t) = 0\n",
    "\\end{align}\n",
    "\n",
    "Consider the initial condition\n",
    "\\begin{align}\n",
    "u(x,0) = \\frac{x}{1 + \\sqrt{\\frac{1}{t_0}} \\exp{\\left(Re \\frac{x^2}{4} \\right)}},\n",
    "\\end{align}\n",
    "\n",
    "Set $L=1$ and maximum time $t_{max} = 2$. An analytical solution exists and is given by \n",
    "\\begin{align}\n",
    "u(x,t) =  \\frac{\\frac{x}{t+1}}{1 + \\sqrt{\\frac{t+1}{t_0}} \\exp{\\left(Re \\frac{x^2}{4t+4} \\right)}}\n",
    "\\end{align}\n",
    "\n",
    "where $t_0 = \\exp{(Re/8)}$ and $Re = 1/\\nu$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab62e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import keras_tuner\n",
    "tf.keras.backend.set_floatx('float64') \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, ScalarFormatter, FormatStrFormatter\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "\n",
    "from matplotlib import animation\n",
    "matplotlib.rc('animation', html='html5')\n",
    "from IPython.display import display\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "# Plot parameters\n",
    "plt.rc('font', family='serif')\n",
    "plt.rcParams.update({'font.size': 20,\n",
    "                     'lines.linewidth': 2,\n",
    "                     'lines.markersize':10,\n",
    "                     'axes.labelsize': 16, # fontsize for x and y labels (was 10)\n",
    "                     'axes.titlesize': 20,\n",
    "                     'xtick.labelsize': 16,\n",
    "                     'ytick.labelsize': 16,\n",
    "                     'legend.fontsize': 16,\n",
    "                     'axes.linewidth': 2})\n",
    "\n",
    "import itertools\n",
    "colors = itertools.cycle(['r','g','b','m','y','c'])\n",
    "markers = itertools.cycle(['p','d','o','^','s','x',]) #'D','H','v','*'])\n",
    "\n",
    "sys.path.append('/home/pgrivera/DeepONet/deeponet/Burgers/functions')\n",
    "sys.path.append('/home/pgrivera/DeepONet/scripts')\n",
    "\n",
    "import don\n",
    "import burgers_exact as bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf629893",
   "metadata": {},
   "outputs": [],
   "source": [
    "case='Train' #or 'Predict'\n",
    "model_path = 'test1'\n",
    "\n",
    "if case == 'Predict':\n",
    "    loaded_model = tf.keras.models.load_model(model_path)\n",
    "    branch_id = np.load(model_path+'/branch_id.npy')\n",
    "\n",
    "train_epochs=10000\n",
    "loss='mse'\n",
    "optimizer_str='adam'\n",
    "scaling=False\n",
    "scaler_min=0\n",
    "scaler_max=1\n",
    "re_train_list=[25,50,100,200,400,800]\n",
    "re_val_list=[10,1000]\n",
    "re_test_list=[10,35,75,150,300,600,1000]\n",
    "x_extent_train=0.8\n",
    "t_extent_train=1.6\n",
    "x_extent_val=1\n",
    "t_extent_val=2\n",
    "percent_branch=0.05\n",
    "percent_trunk=0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b37f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_grid(L, T, vxn, vtn):\n",
    "    vx = np.linspace(0,L,vxn)\n",
    "    vt = np.linspace(0,T,vtn)\n",
    "    return vx, vt\n",
    "\n",
    "def plot_bounds_1d(p1,p2,p3,L,T, label1=None, vmin1=None, vmax1=None, name=None):\n",
    "    \n",
    "    if vmin1 is None:\n",
    "        vmin1 = np.amin([p1.min(), p2.min()])\n",
    "        vmax1 = np.amax([p1.max(), p2.max()])\n",
    "\n",
    "    fig, ((ax1), (ax2), (ax3)) = plt.subplots(1,3, figsize=(20,3))\n",
    "    pcm1 = ax1.imshow(p1,cmap='jet',origin='lower',\n",
    "                      vmin=vmin1, vmax=vmax1, extent=(0,T,0,L), aspect = 0.79)\n",
    "    ax1.yaxis.set_ticks(np.arange(0,L+0.1,1))\n",
    "    fig.colorbar(pcm1,ax=ax1)\n",
    "    ax1.set_title('Truth' +'\\n'+ '%s = %.2f'%('Re', label1)+'\\n'+\n",
    "                 '%.4f<u<%.4f'%(tf.reduce_min(p1).numpy(), tf.reduce_max(p1).numpy()))\n",
    "    pcm2 = ax2.imshow(p2,cmap='jet',origin='lower',\n",
    "                      vmin=vmin1, vmax=vmax1, extent=(0,T,0,L), aspect = 0.79)\n",
    "    ax2.yaxis.set_ticks(np.arange(0,L+0.1,1))\n",
    "\n",
    "    fig.colorbar(pcm2,ax=ax2)\n",
    "    ax2.set_title('Prediction' +'\\n'+ '%s = %.2f'%('Re', label1)+'\\n'\n",
    "                 '%.4f<u<%.4f'%(tf.reduce_min(p2).numpy(), tf.reduce_max(p2).numpy()))\n",
    "    pcm3 = ax3.imshow(p3,cmap='coolwarm',origin='lower',\n",
    "                      vmin=-0.05, vmax=0.05, extent=(0,T,0,L), aspect = 0.79)\n",
    "    ax3.yaxis.set_ticks(np.arange(0,L+0.1,1))\n",
    "\n",
    "    cbar = fig.colorbar(pcm3,ax=ax3)\n",
    "    ax3.set_title('Relative Error' +'\\n'+ '%s = %.2f'%('Re', label1))\n",
    "    \n",
    "    ax1.set_ylabel('$x$',fontsize=18)\n",
    "    ax1.set_xlabel('$t$',fontsize=18)\n",
    "    ax2.set_xlabel('$t$',fontsize=18) \n",
    "    ax3.set_xlabel('$t$',fontsize=18)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "#     plt.savefig(name)\n",
    "\n",
    "def plot_spcaetime_1d(p1,p2,p3,p4,p5,p6,T,L, colormap='jet', label1=None, label2=None, vmin1=None, vmax1=None, name=None):\n",
    "    \"\"\"\n",
    "    Plot space-time 2d plots of 1D solutions\n",
    "    Row1 : Predicted, True, Error for Soln1\n",
    "    Row2 : Predicted, True, Error for Soln2\n",
    "    \"\"\"\n",
    "    f = plt.figure(figsize=(15,10))\n",
    "    gs = gridspec.GridSpec(3, 3, )\n",
    "    gs.update(wspace=0.2, hspace=0.2) # set the spacing between axes.\n",
    "\n",
    "    if vmin1 is None:\n",
    "        vmin1 = np.amin([p1.min(), p2.min(), p3.min(), p4.min()])\n",
    "        vmax1 = np.amax([p1.max(), p2.max(), p3.max(), p4.max()])\n",
    "\n",
    "    ax1 = plt.subplot(gs[0, 0]);\n",
    "    f1= ax1.imshow(p1,cmap=colormap,origin='lower',vmin=vmin1, vmax=vmax1, extent=(0,T,0,L), aspect = 0.59)\n",
    "    ax1.yaxis.set_ticks(np.arange(0,L+0.1,1)); ax1.xaxis.set_ticks(np.arange(0,T+0.1,1))\n",
    "    ax1.set_title('%s=%.2f'%('Re',label1[0]))\n",
    "\n",
    "    ax2 = plt.subplot(gs[0, 1]);\n",
    "    f2 = ax2.imshow(p2,cmap=colormap,origin='lower',vmin=vmin1, vmax=vmax1, extent=(0,T,0,L), aspect = 0.59)\n",
    "    ax2.yaxis.set_ticks(np.arange(0,L+0.1,1)); ax2.xaxis.set_ticks(np.arange(0,T+0.1,1))\n",
    "    ax2.set_title('%s=%.2f'%('Re',label1[1]))\n",
    "\n",
    "    ax3 = plt.subplot(gs[1, 0]);\n",
    "    f3= ax3.imshow(p3,cmap=colormap,origin='lower',vmin=vmin1, vmax=vmax1, extent=(0,T,0,L), aspect = 0.59)\n",
    "    ax3.set_xticklabels([]); ax3.set_yticklabels([])\n",
    "#     ax3.yaxis.set_ticks(np.arange(0,1.1,1))\n",
    "    ax3.set_title('%s=%.2f'%('Re',label1[2]))\n",
    "\n",
    "    ax4 = plt.subplot(gs[1, 1]);\n",
    "    f4 = ax4.imshow(p4,cmap=colormap,origin='lower',vmin=vmin1, vmax=vmax1, extent=(0,T,0,L), aspect = 0.59)\n",
    "    ax4.set_xticklabels([]); ax4.set_yticklabels([])\n",
    "    ax4.set_title('%s=%.2f'%('Re',label1[3]))\n",
    "    \n",
    "    ax5 = plt.subplot(gs[2, 0]);\n",
    "    f5= ax5.imshow(p5,cmap=colormap,origin='lower',vmin=vmin1, vmax=vmax1, extent=(0,T,0,L), aspect = 0.59)\n",
    "    ax5.set_xticklabels([]); ax5.set_yticklabels([])\n",
    "#     ax3.yaxis.set_ticks(np.arange(0,1.1,1))\n",
    "    ax5.set_title('%s=%.2f'%('Re',label1[4]))\n",
    "\n",
    "    ax6 = plt.subplot(gs[2, 1]);\n",
    "    f6 = ax6.imshow(p6,cmap=colormap,origin='lower',vmin=vmin1, vmax=vmax1, extent=(0,T,0,L), aspect = 0.59)\n",
    "    cbar1 = f.colorbar(f6, ax=list((ax1, ax2, ax3, ax4, ax5, ax6)),orientation='horizontal',aspect=50, pad=0.1)\n",
    "    ax6.set_xticklabels([]); ax6.set_yticklabels([])\n",
    "    ax6.set_title('%s=%.2f'%('Re',label1[5]))\n",
    "\n",
    "    ax1.set_ylabel('$x$',fontsize=18); #ax2.set_ylabel('$x$',fontsize=18);\n",
    "    ax3.set_ylabel('$x$',fontsize=18); #ax4.set_ylabel('$x$',fontsize=18);\n",
    "\n",
    "    ax5.set_xlabel('$t$',fontsize=18); ax6.set_xlabel('$t$',fontsize=18); \n",
    "    ax5.set_ylabel('$x$',fontsize=18); #ax6.set_ylabel('$x$',fontsize=18);\n",
    "#     plt.savefig(name)\n",
    "\n",
    "\n",
    "def multiple_burgers(Re_list,vxn,vx,vtn,vt,percent_branch,percent_trunk,id_branch=None):\n",
    "    \n",
    "    number_cases = len(Re_list)\n",
    "    branch_sensors = int(vxn*percent_branch)\n",
    "    trunk_sensors = int(vtn*vxn*percent_trunk)\n",
    "    \n",
    "    burgers_array = np.zeros((number_cases,vxn,vtn))\n",
    "    burgers_flatten = np.zeros((number_cases*vxn*vtn))\n",
    "    count = 0 \n",
    "    id0 = 0\n",
    "    id1 = vxn*vtn\n",
    "    \n",
    "    for Re in Re_list:\n",
    "        solution = np.zeros((vxn,vtn))\n",
    "        for ix,vxi in enumerate(vx):\n",
    "            solution[ix] = bg.true_solution(vxi,vt,Re)\n",
    "        burgers_array[count] = solution\n",
    "        burgers_flatten[id0:id1] = (solution.flatten())\n",
    "        count = count + 1\n",
    "        id0 = id1\n",
    "        id1 = id1 + vxn*vtn\n",
    "        \n",
    "    b0 = burgers_array[:,:,0] #u0\n",
    "    \n",
    "    if id_branch is not None:\n",
    "        id_b=np.zeros(np.shape(id_branch),dtype=int)\n",
    "        for i in range(len(id_branch[0])):\n",
    "            smallest=np.absolute(vx-id_branch[1][i])\n",
    "            id_b[0][i]=int(np.argmin(smallest))\n",
    "        id_b[1]=id_branch[1]    \n",
    "    else:\n",
    "        id_b = np.sort(np.random.choice(vxn, branch_sensors, replace=False))\n",
    "        b_coords = vx[id_b]\n",
    "        id_b = [id_b, b_coords]\n",
    "\n",
    "    b0_train = b0[:,id_b[0]]\n",
    "\n",
    "    \n",
    "    T, X = np.meshgrid(vt,vx)\n",
    "    for i in range(number_cases):\n",
    "        b0_vector = np.tile(np.expand_dims(b0_train[i],1),vtn*vxn).T\n",
    "        \n",
    "        id_t = np.sort(np.random.choice(vtn*vxn, trunk_sensors, replace=False))\n",
    "        \n",
    "        if i == 0:\n",
    "            b_input = b0_vector[id_t]\n",
    "            t_input = np.hstack([T.flatten()[id_t,None], X.flatten()[id_t,None]])\n",
    "            target = burgers_array[i,:,:].flatten()[id_t,None]\n",
    "\n",
    "        else:\n",
    "            b_input = np.vstack([b_input,b0_vector[id_t]])\n",
    "            t_input = np.vstack([t_input,np.hstack([T.flatten()[id_t,None], X.flatten()[id_t,None]])])\n",
    "            target = np.vstack([target,burgers_array[i,:,:].flatten()[id_t,None]])        \n",
    "    \n",
    "    return burgers_array, burgers_flatten, b_input, t_input, target, id_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5ac4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re_train = [15,25,50,75,100,150,200,300,400,600,800,900]\n",
    "Re_train =  re_train_list\n",
    "L_train =  x_extent_train\n",
    "T_train =  t_extent_train\n",
    "vxn = 300\n",
    "vtn = 500\n",
    "vx, vt = define_grid(L_train, T_train, vxn, vtn)\n",
    "percent_branch =  percent_branch\n",
    "percent_trunk =  percent_trunk\n",
    "burgers_array_train, burgers_flatten_train, b_train, \\\n",
    "                    t_train, target_train, id_branch = multiple_burgers(Re_train,vxn,vx,vtn,vt,\n",
    "                                                            percent_branch,percent_trunk)\n",
    "\n",
    "if case == 'Predict':\n",
    "    id_branch=branch_id\n",
    "    \n",
    "Re_val =  re_val_list\n",
    "L_val =  x_extent_val\n",
    "T_val =  t_extent_val\n",
    "vxn = 300\n",
    "vtn = 500\n",
    "vx, vt = define_grid(L_val, T_val, vxn, vtn)\n",
    "percent_branch =  percent_branch\n",
    "percent_trunk =  percent_trunk\n",
    "burgers_array_val, burgers_flatten_val, b_val, \\\n",
    "                    t_val, target_val, _ = multiple_burgers(Re_val,vxn,vx,vtn,vt,\n",
    "                                                         percent_branch,percent_trunk,id_branch=id_branch)\n",
    "\n",
    "Re_test =  re_test_list\n",
    "L_test = L_val\n",
    "T_test = T_val\n",
    "vxn = 300\n",
    "vtn = 500\n",
    "vx, vt = define_grid(L_test, T_test, vxn, vtn)\n",
    "percent_branch = 0.05\n",
    "percent_trunk = 1\n",
    "burgers_array_test, burgers_flatten_test, b_test, \\\n",
    "                    t_test, target_test, _ = multiple_burgers(Re_test,vxn,vx,vtn,vt, \n",
    "                                                              percent_branch,percent_trunk,id_branch)\n",
    "\n",
    "if  scaling is True:\n",
    "    x_scaler = MinMaxScaler(feature_range=( scaler_min,  scaler_max))\n",
    "    t_scaler = MinMaxScaler(feature_range=( scaler_min,  scaler_max))\n",
    "    u_scaler = MinMaxScaler(feature_range=( scaler_min,  scaler_max))\n",
    "    b_scaler = MinMaxScaler(feature_range=( scaler_min,  scaler_max))\n",
    "\n",
    "    x_scaler.fit(np.expand_dims(t_val[:,0],1))\n",
    "    t_scaler.fit(np.expand_dims(t_val[:,1],1))\n",
    "    u_scaler.fit(target_val)\n",
    "    b_scaler.fit(b_val)\n",
    "\n",
    "    t_train[:,0] = np.squeeze(x_scaler.transform(np.expand_dims(t_train[:,0],1)))\n",
    "    t_train[:,1] = np.squeeze(t_scaler.transform(np.expand_dims(t_train[:,1],1)))\n",
    "    b_train = b_scaler.transform(b_train)\n",
    "    target_train = u_scaler.transform(target_train)\n",
    "    \n",
    "    t_val[:,0] = np.squeeze(x_scaler.transform(np.expand_dims(t_val[:,0],1)))\n",
    "    t_val[:,1] = np.squeeze(t_scaler.transform(np.expand_dims(t_val[:,1],1)))\n",
    "    b_val = b_scaler.transform(b_val)\n",
    "    target_val = u_scaler.transform(target_val)\n",
    "    \n",
    "    t_test[:,0] = np.squeeze(x_scaler.transform(np.expand_dims(t_test[:,0],1)))\n",
    "    t_test[:,1] = np.squeeze(t_scaler.transform(np.expand_dims(t_test[:,1],1)))\n",
    "    b_test = b_scaler.transform(b_test)\n",
    "    target_test = u_scaler.transform(target_test)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6642a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_sensors = int(vxn* percent_branch)\n",
    "\n",
    "    \n",
    "\n",
    "nn = don.don_nn(branch_sensors, \n",
    "                2, \n",
    "                6,\n",
    "                256,\n",
    "                'relu',\n",
    "                'glorot_normal',                \n",
    "                'l2')\n",
    "\n",
    "model = don.don_model(nn)\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.9,\n",
    "                          patience=100, min_lr=1e-6, min_delta=1e-10, verbose=1)\n",
    "\n",
    "if optimizer_str == \"adam\":\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "elif optimizer_str == \"rmsprop\":   \n",
    "    optimizer = tf.keras.optimizers.RMSprop()\n",
    "\n",
    "if  loss == \"mse\":\n",
    "    loss_obj = tf.keras.losses.MeanSquaredError()\n",
    "elif  loss == \"mae\":   \n",
    "    loss_obj = tf.keras.losses.MeanAbsoluteError()\n",
    "\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss_fn = loss_obj)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Prepare the dataset.\n",
    "percent_trunk =  percent_trunk\n",
    "batch_size = int(vtn*vxn*percent_trunk*len( re_train_list))\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((b_train,t_train, target_train))\n",
    "dataset = dataset.shuffle(buffer_size=batch_size).batch(batch_size)\n",
    "\n",
    "batch_size = int(vtn*vxn* percent_trunk*len( re_val_list))\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((b_val,t_val, target_val))\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.9,\n",
    "                              patience=100, min_lr=1e-6, min_delta=1e-10, verbose=1)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=1e-8,\n",
    "    patience=500,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "i=1\n",
    "\n",
    "if case == 'Train':\n",
    "    model.fit(dataset, validation_data=val_dataset, epochs= train_epochs,\n",
    "                 callbacks=[tf.keras.callbacks.TensorBoard(\"tb/train_logs\"+str(i)),reduce_lr,early_stop])\n",
    "\n",
    "    model.save('test'+str(i),id_branch,)\n",
    "\n",
    "if case == 'Predict':   \n",
    "    model = loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879933b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_t = np.argmin(np.abs(vt-1.6))\n",
    "id_x = np.argmin(np.abs(vx-0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e2a648",
   "metadata": {},
   "outputs": [],
   "source": [
    "o_res = model([b_test,t_test])\n",
    "\n",
    "if  scaling is True:\n",
    "    o_res = u_scaler.inverse_transform(o_res)\n",
    "\n",
    "test = np.reshape(np.array(o_res),(len( re_test_list),vxn,vtn))\n",
    "\n",
    "error = test - burgers_array_test\n",
    "\n",
    "plot_bounds_1d(burgers_array_test[0],test[0],error[0], L_test, T_test, label1= re_test_list[0], vmin1=0, vmax1=0.5,name='low_re'+str(i))\n",
    "plot_bounds_1d(burgers_array_test[-1],test[-1],error[-1], L_test, T_test, label1= re_test_list[-1], vmin1=0, vmax1=0.5, name='high_re'+str(i))\n",
    "\n",
    "test[:,:,id_t]=1000\n",
    "test[:,id_x,:]=1000\n",
    "burgers_array_test[:,:,id_t]=1000\n",
    "burgers_array_test[:,id_x,:]=1000\n",
    "error[:,:,id_t]=1000\n",
    "error[:,id_x,:]=1000\n",
    "\n",
    "plot_spcaetime_1d(test[0],test[1],\n",
    "                  test[2],test[3],\n",
    "                  test[4],test[5],\n",
    "                  T_test,L_test,label1= re_test_list,\n",
    "                  vmin1=0,\n",
    "                  vmax1=0.5,                      \n",
    "                  name='prediction'+str(i))\n",
    "\n",
    "plot_spcaetime_1d(error[0],error[1],\n",
    "                  error[2],error[3],\n",
    "                  error[4],error[5],\n",
    "                  T_test,L_test,\n",
    "                  colormap='coolwarm',label1= re_test_list,\n",
    "                  vmin1=-0.05,\n",
    "                  vmax1=0.05,\n",
    "                  name='error'+str(i))\n",
    "\n",
    "plot_spcaetime_1d(burgers_array_train[0],burgers_array_train[1],\n",
    "                  burgers_array_train[2],burgers_array_train[3],\n",
    "                  burgers_array_train[4],burgers_array_train[5],\n",
    "                  T_train,L_train,label1= re_train_list,\n",
    "                  vmin1=0,\n",
    "                  vmax1=0.5,                  \n",
    "                  name='train') \n",
    "\n",
    "plot_spcaetime_1d(burgers_array_test[0],burgers_array_test[1],\n",
    "                  burgers_array_test[2],burgers_array_test[3],\n",
    "                  burgers_array_test[4],burgers_array_test[5],\n",
    "                  T_test,L_test,label1= re_test_list,\n",
    "                  vmin1=0,\n",
    "                  vmax1=0.5,    \n",
    "                  name='truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61932dee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
